{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"41f3PT5RG3P2","colab_type":"code","outputId":"b48392bd-687f-4523-bd40-88fa91fc1ce6","executionInfo":{"status":"error","timestamp":1569936468218,"user_tz":-120,"elapsed":8191532,"user":{"displayName":"cecilia carolina aponte peredo","photoUrl":"","userId":"10052863272833414084"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Cecilia Aponte\n","# AI - Reinforcement Learning\n","# Breakout\n","\n","# This only needs to be done once per notebook.\n","# Install the PyDrive wrapper & import libraries.\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","your_module = drive.CreateFile({'id':'17C0gsmd0Ujipwrzm1xibvcKRx78KMS02'})\n","your_module.GetContentFile('deepqnet.py')\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","# !ls /content/gdrive/My\\ Drive/Breakout_Project/\n","\n","\n","import gym\n","from deepqnet import *\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","\n","# remove information of the image that is not needed, score, or rgb color (only one channel)\n","def preprocess(observation):\n","    observation = observation / 255\n","    obs = np.mean(observation[30:, :], axis=2).reshape(180,160,1)\n","    return obs\n","\n","\n","# stack the frames so agent understands the motion\n","def stackFrames(stacked_frames, frame, bufferSize):\n","    if stacked_frames is None: # initialize\n","        stacked_frames = np.zeros((bufferSize, *frame.shape))\n","        for id,_ in enumerate(stacked_frames):\n","            stacked_frames[id,:] = frame\n","    else: # stack the frames chosen\n","        stacked_frames[0:bufferSize-1,:] = stacked_frames[1:,:]\n","        stacked_frames[bufferSize-1, :] = frame\n","    stacked_frames = stacked_frames.reshape(*frame.shape[0:2], bufferSize)\n","\n","    return stacked_frames\n","\n","# Plot the results\n","def plot(x, scores, epsHist, rewards):\n","    fig, axs = plt.subplots(3)\n","    axs[0].plot( x, scores, marker='o', markerfacecolor='green', markersize=5, color='green', linewidth=4)\n","    axs[1].plot( x, epsHist, marker='', color='blue', linewidth=4)\n","    axs[2].plot( x, rewards, marker='', color='purple', linewidth=4, linestyle='dashed', label=\"rewards\")\n","\n","    plt.xticks(np.arange(min(x), max(x)+1, 1.0))\n","    plt.xlabel('Episodes', fontsize=10)\n","    axs[0].set_ylabel('Score', fontsize=10)\n","    axs[1].set_ylabel('Epsilon', fontsize=10)\n","    axs[2].set_ylabel('Reward', fontsize=10)\n","\n","    for ax in axs.flat:\n","        ax.label_outer()\n","\n","    fig.suptitle('Change in Score, Epsilon, and Reward with Time', fontsize=15)\n","    plt.show()\n","\n","\n","if __name__ == '__main__':\n","    env = gym.make('Breakout-v0')\n","    loadCkpt = False\n","    agent = Agent(epsilon=1.0, gamma=0.99, alpha=0.005, inputDims=(180,160,4), nActions=4, MemSize=10000, batchSize=64)\n","\n","    if loadCkpt:\n","        agent.loadModels()\n","\n","    scores = []\n","    epsHist = []\n","    rewards = []\n","    nGames = 800 # games per epoch to get reward\n","    stackSize = 4\n","    score = 0\n","    nSteps = 0\n","\n","\n","    for i in range(nGames):\n","        done = False\n","\n","        observation = env.reset()\n","        observation = preprocess(observation)\n","        stacked_frames = None\n","        observation = stackFrames(stacked_frames, observation, stackSize)\n","        score = 0\n","        totRewards = 0\n","        while not done:\n","            action = agent.chooseAction(observation)\n","            obsNext, reward, done, info = env.step(action)\n","            reward = np.clip(reward, -1, 1)\n","            if done == True:\n","                reward = -1\n","            totRewards += reward\n","            nSteps += 1\n","            obsNext = stackFrames(stacked_frames, preprocess(obsNext), stackSize)\n","            score += reward\n","            agent.storeTransition(observation, action, reward, obsNext, int(done))\n","            observation = obsNext\n","\n","\n","            if nSteps % 5 == 0:\n","                agent.learning()\n","              \n","        if i % 20 == 0 and i > 0:\n","            # to see if agent score is increasing (agent is learning)\n","            avg_score = np.mean(scores[max(0, i-10):(i+1)])\n","            print('episode: ', i, '\\t','score: ', score, '\\t',\n","                 ' average score %.3f: ' % avg_score, '\\t',\n","                'epsilon: %.3f ' % agent.epsilon, '\\t Total Reward: ', totRewards)\n","        else:\n","            print('episode: ', i, '\\t','score: ', score, '\\t epsilon: %.3f ' % agent.epsilon, '\\t reward: ', reward)\n","        epsHist.append(agent.epsilon)\n","        scores.append(score)\n","        rewards.append(reward)\n","    x = [i+1 for i in range(nGames)]\n","    \n","    plot(x, scores, epsHist, reward)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/deepqnet.py:25: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /content/deepqnet.py:38: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/deepqnet.py:40: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6b1f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6b1f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6b1f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6b1f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dd6bdba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dd6b1ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dd6b1ef0>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dd6b1ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dd6b1ef0>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd636e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd636e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd636e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd636e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd653198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd653198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd653198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70dd653198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /content/deepqnet.py:68: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n","\n","WARNING:tensorflow:From /content/deepqnet.py:27: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From /content/deepqnet.py:32: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f70dcfe3eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f719660c4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f719660c4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f719660c4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f719660c4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dcfb4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dcfb4710>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dcfb4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f70dcfb4710>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7149fabc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7149fabc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7149fabc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7149fabc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70de591c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70de591c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70de591c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f70de591c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","episode:  0 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  1 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  2 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  3 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  4 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  5 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  6 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  7 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  8 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  9 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  10 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  11 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  12 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  13 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  14 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  15 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  16 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  17 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  18 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  19 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  20 \t score:  0.0 \t  average score 0.000:  \t epsilon: 1.000  \t Total Reward:  0.0\n","episode:  21 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  22 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  23 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  24 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  25 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  26 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  27 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  28 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  29 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  30 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  31 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  32 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  33 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  34 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  35 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  36 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  37 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  38 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  39 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  40 \t score:  2.0 \t  average score 0.400:  \t epsilon: 1.000  \t Total Reward:  2.0\n","episode:  41 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  42 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  43 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  44 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  45 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  46 \t score:  5.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  47 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  48 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  49 \t score:  4.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  50 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  51 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  52 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  53 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  54 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  55 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  56 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  57 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  58 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  59 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  60 \t score:  1.0 \t  average score 0.000:  \t epsilon: 1.000  \t Total Reward:  1.0\n","episode:  61 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  62 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  63 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  64 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  65 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  66 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  67 \t score:  4.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  68 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  69 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  70 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  71 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  72 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  73 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  74 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  75 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  76 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  77 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  78 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  79 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  80 \t score:  0.0 \t  average score 0.400:  \t epsilon: 1.000  \t Total Reward:  0.0\n","episode:  81 \t score:  4.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  82 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  83 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  84 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  85 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  86 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  87 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  88 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  89 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  90 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  91 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  92 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  93 \t score:  4.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  94 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  95 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  96 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  97 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  98 \t score:  3.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  99 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  100 \t score:  1.0 \t  average score 0.800:  \t epsilon: 1.000  \t Total Reward:  1.0\n","episode:  101 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  102 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  103 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  104 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  105 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  106 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  107 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  108 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  109 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  110 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  111 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  112 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  113 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  114 \t score:  3.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  115 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  116 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  117 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  118 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  119 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  120 \t score:  2.0 \t  average score 0.200:  \t epsilon: 1.000  \t Total Reward:  2.0\n","episode:  121 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  122 \t score:  3.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  123 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  124 \t score:  5.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  125 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  126 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  127 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  128 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  129 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  130 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  131 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  132 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  133 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  134 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  135 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  136 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  137 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  138 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  139 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  140 \t score:  1.0 \t  average score 0.200:  \t epsilon: 1.000  \t Total Reward:  1.0\n","episode:  141 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  142 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  143 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  144 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  145 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  146 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  147 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  148 \t score:  2.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  149 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  150 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  151 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  152 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  153 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  154 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  155 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  156 \t score:  0.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  157 \t score:  -1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  158 \t score:  1.0 \t epsilon: 1.000  \t reward:  -1\n","episode:  159 \t score:  -1.0 \t epsilon: 0.998  \t reward:  -1\n","episode:  160 \t score:  1.0 \t  average score 0.100:  \t epsilon: 0.992  \t Total Reward:  1.0\n","episode:  161 \t score:  2.0 \t epsilon: 0.985  \t reward:  -1\n","episode:  162 \t score:  1.0 \t epsilon: 0.980  \t reward:  -1\n","episode:  163 \t score:  -1.0 \t epsilon: 0.976  \t reward:  -1\n","episode:  164 \t score:  1.0 \t epsilon: 0.970  \t reward:  -1\n","episode:  165 \t score:  -1.0 \t epsilon: 0.966  \t reward:  -1\n","episode:  166 \t score:  -1.0 \t epsilon: 0.962  \t reward:  -1\n","episode:  167 \t score:  -1.0 \t epsilon: 0.959  \t reward:  -1\n","episode:  168 \t score:  0.0 \t epsilon: 0.954  \t reward:  -1\n","episode:  169 \t score:  0.0 \t epsilon: 0.949  \t reward:  -1\n","episode:  170 \t score:  0.0 \t epsilon: 0.945  \t reward:  -1\n","episode:  171 \t score:  0.0 \t epsilon: 0.940  \t reward:  -1\n","episode:  172 \t score:  0.0 \t epsilon: 0.936  \t reward:  -1\n","episode:  173 \t score:  1.0 \t epsilon: 0.930  \t reward:  -1\n","episode:  174 \t score:  1.0 \t epsilon: 0.925  \t reward:  -1\n","episode:  175 \t score:  0.0 \t epsilon: 0.920  \t reward:  -1\n","episode:  176 \t score:  -1.0 \t epsilon: 0.917  \t reward:  -1\n","episode:  177 \t score:  0.0 \t epsilon: 0.912  \t reward:  -1\n","episode:  178 \t score:  1.0 \t epsilon: 0.906  \t reward:  -1\n","episode:  179 \t score:  3.0 \t epsilon: 0.898  \t reward:  -1\n","episode:  180 \t score:  -1.0 \t  average score 0.500:  \t epsilon: 0.895  \t Total Reward:  -1.0\n","episode:  181 \t score:  -1.0 \t epsilon: 0.891  \t reward:  -1\n","episode:  182 \t score:  -1.0 \t epsilon: 0.887  \t reward:  -1\n","episode:  183 \t score:  2.0 \t epsilon: 0.881  \t reward:  -1\n","episode:  184 \t score:  0.0 \t epsilon: 0.876  \t reward:  -1\n","episode:  185 \t score:  1.0 \t epsilon: 0.871  \t reward:  -1\n","episode:  186 \t score:  0.0 \t epsilon: 0.866  \t reward:  -1\n","episode:  187 \t score:  1.0 \t epsilon: 0.860  \t reward:  -1\n","episode:  188 \t score:  1.0 \t epsilon: 0.855  \t reward:  -1\n","episode:  189 \t score:  0.0 \t epsilon: 0.850  \t reward:  -1\n","episode:  190 \t score:  1.0 \t epsilon: 0.844  \t reward:  -1\n","episode:  191 \t score:  1.0 \t epsilon: 0.838  \t reward:  -1\n","episode:  192 \t score:  -1.0 \t epsilon: 0.835  \t reward:  -1\n","episode:  193 \t score:  0.0 \t epsilon: 0.831  \t reward:  -1\n","episode:  194 \t score:  -1.0 \t epsilon: 0.827  \t reward:  -1\n","episode:  195 \t score:  2.0 \t epsilon: 0.820  \t reward:  -1\n","episode:  196 \t score:  -1.0 \t epsilon: 0.817  \t reward:  -1\n","episode:  197 \t score:  0.0 \t epsilon: 0.812  \t reward:  -1\n","episode:  198 \t score:  -1.0 \t epsilon: 0.808  \t reward:  -1\n","episode:  199 \t score:  -1.0 \t epsilon: 0.805  \t reward:  -1\n","episode:  200 \t score:  1.0 \t  average score -0.100:  \t epsilon: 0.799  \t Total Reward:  1.0\n","episode:  201 \t score:  0.0 \t epsilon: 0.794  \t reward:  -1\n","episode:  202 \t score:  1.0 \t epsilon: 0.789  \t reward:  -1\n","episode:  203 \t score:  0.0 \t epsilon: 0.784  \t reward:  -1\n","episode:  204 \t score:  -1.0 \t epsilon: 0.780  \t reward:  -1\n","episode:  205 \t score:  -1.0 \t epsilon: 0.777  \t reward:  -1\n","episode:  206 \t score:  -1.0 \t epsilon: 0.773  \t reward:  -1\n","episode:  207 \t score:  -1.0 \t epsilon: 0.769  \t reward:  -1\n","episode:  208 \t score:  1.0 \t epsilon: 0.763  \t reward:  -1\n","episode:  209 \t score:  1.0 \t epsilon: 0.758  \t reward:  -1\n","episode:  210 \t score:  1.0 \t epsilon: 0.753  \t reward:  -1\n","episode:  211 \t score:  -1.0 \t epsilon: 0.749  \t reward:  -1\n","episode:  212 \t score:  -1.0 \t epsilon: 0.745  \t reward:  -1\n","episode:  213 \t score:  2.0 \t epsilon: 0.739  \t reward:  -1\n","episode:  214 \t score:  -1.0 \t epsilon: 0.736  \t reward:  -1\n","episode:  215 \t score:  1.0 \t epsilon: 0.730  \t reward:  -1\n","episode:  216 \t score:  -1.0 \t epsilon: 0.726  \t reward:  -1\n","episode:  217 \t score:  0.0 \t epsilon: 0.722  \t reward:  -1\n","episode:  218 \t score:  2.0 \t epsilon: 0.715  \t reward:  -1\n","episode:  219 \t score:  0.0 \t epsilon: 0.710  \t reward:  -1\n","episode:  220 \t score:  3.0 \t  average score 0.200:  \t epsilon: 0.702  \t Total Reward:  3.0\n","episode:  221 \t score:  0.0 \t epsilon: 0.697  \t reward:  -1\n","episode:  222 \t score:  -1.0 \t epsilon: 0.694  \t reward:  -1\n","episode:  223 \t score:  -1.0 \t epsilon: 0.690  \t reward:  -1\n","episode:  224 \t score:  1.0 \t epsilon: 0.684  \t reward:  -1\n","episode:  225 \t score:  2.0 \t epsilon: 0.677  \t reward:  -1\n","episode:  226 \t score:  1.0 \t epsilon: 0.672  \t reward:  -1\n","episode:  227 \t score:  -1.0 \t epsilon: 0.668  \t reward:  -1\n","episode:  228 \t score:  1.0 \t epsilon: 0.662  \t reward:  -1\n","episode:  229 \t score:  2.0 \t epsilon: 0.655  \t reward:  -1\n","episode:  230 \t score:  4.0 \t epsilon: 0.646  \t reward:  -1\n","episode:  231 \t score:  1.0 \t epsilon: 0.640  \t reward:  -1\n","episode:  232 \t score:  -1.0 \t epsilon: 0.636  \t reward:  -1\n","episode:  233 \t score:  2.0 \t epsilon: 0.629  \t reward:  -1\n","episode:  234 \t score:  0.0 \t epsilon: 0.624  \t reward:  -1\n","episode:  235 \t score:  2.0 \t epsilon: 0.618  \t reward:  -1\n","episode:  236 \t score:  4.0 \t epsilon: 0.608  \t reward:  -1\n","episode:  237 \t score:  4.0 \t epsilon: 0.598  \t reward:  -1\n","episode:  238 \t score:  1.0 \t epsilon: 0.592  \t reward:  -1\n","episode:  239 \t score:  -1.0 \t epsilon: 0.588  \t reward:  -1\n","episode:  240 \t score:  1.0 \t  average score 1.600:  \t epsilon: 0.582  \t Total Reward:  1.0\n","episode:  241 \t score:  -1.0 \t epsilon: 0.578  \t reward:  -1\n","episode:  242 \t score:  1.0 \t epsilon: 0.573  \t reward:  -1\n","episode:  243 \t score:  1.0 \t epsilon: 0.567  \t reward:  -1\n","episode:  244 \t score:  1.0 \t epsilon: 0.561  \t reward:  -1\n","episode:  245 \t score:  2.0 \t epsilon: 0.554  \t reward:  -1\n","episode:  246 \t score:  2.0 \t epsilon: 0.548  \t reward:  -1\n","episode:  247 \t score:  -1.0 \t epsilon: 0.544  \t reward:  -1\n","episode:  248 \t score:  1.0 \t epsilon: 0.538  \t reward:  -1\n","episode:  249 \t score:  1.0 \t epsilon: 0.533  \t reward:  -1\n","episode:  250 \t score:  1.0 \t epsilon: 0.527  \t reward:  -1\n","episode:  251 \t score:  -1.0 \t epsilon: 0.523  \t reward:  -1\n","episode:  252 \t score:  2.0 \t epsilon: 0.516  \t reward:  -1\n","episode:  253 \t score:  1.0 \t epsilon: 0.510  \t reward:  -1\n","episode:  254 \t score:  -1.0 \t epsilon: 0.506  \t reward:  -1\n","episode:  255 \t score:  -1.0 \t epsilon: 0.502  \t reward:  -1\n","episode:  256 \t score:  3.0 \t epsilon: 0.494  \t reward:  -1\n","episode:  257 \t score:  1.0 \t epsilon: 0.488  \t reward:  -1\n","episode:  258 \t score:  -1.0 \t epsilon: 0.484  \t reward:  -1\n","episode:  259 \t score:  -1.0 \t epsilon: 0.480  \t reward:  -1\n","episode:  260 \t score:  1.0 \t  average score 0.300:  \t epsilon: 0.474  \t Total Reward:  1.0\n","episode:  261 \t score:  -1.0 \t epsilon: 0.470  \t reward:  -1\n","episode:  262 \t score:  -1.0 \t epsilon: 0.466  \t reward:  -1\n","episode:  263 \t score:  2.0 \t epsilon: 0.459  \t reward:  -1\n","episode:  264 \t score:  2.0 \t epsilon: 0.452  \t reward:  -1\n","episode:  265 \t score:  -1.0 \t epsilon: 0.448  \t reward:  -1\n","episode:  266 \t score:  1.0 \t epsilon: 0.442  \t reward:  -1\n","episode:  267 \t score:  1.0 \t epsilon: 0.436  \t reward:  -1\n","episode:  268 \t score:  -1.0 \t epsilon: 0.433  \t reward:  -1\n","episode:  269 \t score:  -1.0 \t epsilon: 0.428  \t reward:  -1\n","episode:  270 \t score:  -1.0 \t epsilon: 0.424  \t reward:  -1\n","episode:  271 \t score:  0.0 \t epsilon: 0.419  \t reward:  -1\n","episode:  272 \t score:  2.0 \t epsilon: 0.412  \t reward:  -1\n","episode:  273 \t score:  1.0 \t epsilon: 0.407  \t reward:  -1\n","episode:  274 \t score:  3.0 \t epsilon: 0.398  \t reward:  -1\n","episode:  275 \t score:  1.0 \t epsilon: 0.392  \t reward:  -1\n","episode:  276 \t score:  1.0 \t epsilon: 0.386  \t reward:  -1\n","episode:  277 \t score:  1.0 \t epsilon: 0.381  \t reward:  -1\n","episode:  278 \t score:  1.0 \t epsilon: 0.375  \t reward:  -1\n","episode:  279 \t score:  3.0 \t epsilon: 0.366  \t reward:  -1\n","episode:  280 \t score:  6.0 \t  average score 1.200:  \t epsilon: 0.353  \t Total Reward:  6.0\n","episode:  281 \t score:  -1.0 \t epsilon: 0.349  \t reward:  -1\n","episode:  282 \t score:  -1.0 \t epsilon: 0.345  \t reward:  -1\n","episode:  283 \t score:  3.0 \t epsilon: 0.336  \t reward:  -1\n","episode:  284 \t score:  1.0 \t epsilon: 0.330  \t reward:  -1\n","episode:  285 \t score:  2.0 \t epsilon: 0.323  \t reward:  -1\n","episode:  286 \t score:  1.0 \t epsilon: 0.317  \t reward:  -1\n","episode:  287 \t score:  0.0 \t epsilon: 0.312  \t reward:  -1\n","episode:  288 \t score:  3.0 \t epsilon: 0.304  \t reward:  -1\n","episode:  289 \t score:  3.0 \t epsilon: 0.297  \t reward:  -1\n","episode:  290 \t score:  1.0 \t epsilon: 0.290  \t reward:  -1\n","episode:  291 \t score:  2.0 \t epsilon: 0.284  \t reward:  -1\n","episode:  292 \t score:  2.0 \t epsilon: 0.276  \t reward:  -1\n","episode:  293 \t score:  -1.0 \t epsilon: 0.272  \t reward:  -1\n","episode:  294 \t score:  -1.0 \t epsilon: 0.269  \t reward:  -1\n","episode:  295 \t score:  1.0 \t epsilon: 0.263  \t reward:  -1\n","episode:  296 \t score:  2.0 \t epsilon: 0.256  \t reward:  -1\n","episode:  297 \t score:  4.0 \t epsilon: 0.247  \t reward:  -1\n","episode:  298 \t score:  3.0 \t epsilon: 0.238  \t reward:  -1\n","episode:  299 \t score:  -1.0 \t epsilon: 0.234  \t reward:  -1\n","episode:  300 \t score:  0.0 \t  average score 1.200:  \t epsilon: 0.228  \t Total Reward:  0.0\n","episode:  301 \t score:  -1.0 \t epsilon: 0.223  \t reward:  -1\n","episode:  302 \t score:  0.0 \t epsilon: 0.218  \t reward:  -1\n","episode:  303 \t score:  0.0 \t epsilon: 0.214  \t reward:  -1\n","episode:  304 \t score:  1.0 \t epsilon: 0.207  \t reward:  -1\n","episode:  305 \t score:  0.0 \t epsilon: 0.202  \t reward:  -1\n","episode:  306 \t score:  0.0 \t epsilon: 0.197  \t reward:  -1\n","episode:  307 \t score:  -1.0 \t epsilon: 0.193  \t reward:  -1\n","episode:  308 \t score:  -1.0 \t epsilon: 0.190  \t reward:  -1\n","episode:  309 \t score:  -1.0 \t epsilon: 0.186  \t reward:  -1\n","episode:  310 \t score:  2.0 \t epsilon: 0.178  \t reward:  -1\n","episode:  311 \t score:  2.0 \t epsilon: 0.171  \t reward:  -1\n","episode:  312 \t score:  1.0 \t epsilon: 0.166  \t reward:  -1\n","episode:  313 \t score:  1.0 \t epsilon: 0.157  \t reward:  -1\n","episode:  314 \t score:  2.0 \t epsilon: 0.150  \t reward:  -1\n","episode:  315 \t score:  1.0 \t epsilon: 0.144  \t reward:  -1\n","episode:  316 \t score:  1.0 \t epsilon: 0.139  \t reward:  -1\n","episode:  317 \t score:  0.0 \t epsilon: 0.134  \t reward:  -1\n","episode:  318 \t score:  1.0 \t epsilon: 0.128  \t reward:  -1\n","episode:  319 \t score:  1.0 \t epsilon: 0.120  \t reward:  -1\n","episode:  320 \t score:  1.0 \t  average score 1.200:  \t epsilon: 0.112  \t Total Reward:  1.0\n","episode:  321 \t score:  -1.0 \t epsilon: 0.108  \t reward:  -1\n","episode:  322 \t score:  1.0 \t epsilon: 0.100  \t reward:  -1\n","episode:  323 \t score:  1.0 \t epsilon: 0.087  \t reward:  -1\n","episode:  324 \t score:  2.0 \t epsilon: 0.079  \t reward:  -1\n","episode:  325 \t score:  3.0 \t epsilon: 0.070  \t reward:  -1\n","episode:  326 \t score:  2.0 \t epsilon: 0.059  \t reward:  -1\n","episode:  327 \t score:  4.0 \t epsilon: 0.048  \t reward:  -1\n","episode:  328 \t score:  1.0 \t epsilon: 0.034  \t reward:  -1\n","episode:  329 \t score:  1.0 \t epsilon: 0.012  \t reward:  -1\n","episode:  330 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  331 \t score:  4.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  332 \t score:  0.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  333 \t score:  0.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  334 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  335 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  336 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  337 \t score:  6.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  338 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  339 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  340 \t score:  5.0 \t  average score 1.400:  \t epsilon: 0.010  \t Total Reward:  5.0\n","episode:  341 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  342 \t score:  0.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  343 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  344 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  345 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  346 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  347 \t score:  4.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  348 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  349 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  350 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  351 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  352 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  353 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  354 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  355 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  356 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  357 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  358 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  359 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  360 \t score:  1.0 \t  average score 0.300:  \t epsilon: 0.010  \t Total Reward:  1.0\n","episode:  361 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  362 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  363 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  364 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  365 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  366 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  367 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  368 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  369 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  370 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  371 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  372 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  373 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  374 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  375 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  376 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  377 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  378 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  379 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  380 \t score:  2.0 \t  average score 1.600:  \t epsilon: 0.010  \t Total Reward:  2.0\n","episode:  381 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  382 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  383 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  384 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  385 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  386 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  387 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  388 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  389 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  390 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  391 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  392 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  393 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  394 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  395 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  396 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  397 \t score:  0.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  398 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  399 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  400 \t score:  1.0 \t  average score 0.900:  \t epsilon: 0.010  \t Total Reward:  1.0\n","episode:  401 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  402 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  403 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  404 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  405 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  406 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  407 \t score:  0.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  408 \t score:  1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  409 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  410 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  411 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  412 \t score:  3.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  413 \t score:  4.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  414 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  415 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  416 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  417 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  418 \t score:  2.0 \t epsilon: 0.010  \t reward:  -1\n","episode:  419 \t score:  -1.0 \t epsilon: 0.010  \t reward:  -1\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d4d0d6192e17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnSteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/deepqnet.py\u001b[0m in \u001b[0;36mlearning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# 3- Calculate current action and next maximum action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         qEval = self.qEval.sess.run(self.qEval.Q,\n\u001b[0;32m--> 173\u001b[0;31m                             feed_dict={self.qEval.input : stateBatch})\n\u001b[0m\u001b[1;32m    174\u001b[0m         qNext = self.qNext.sess.run(self.qNext.Q,\n\u001b[1;32m    175\u001b[0m                             feed_dict={self.qNext.input : newStateBatch})\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m           if (not is_tensor_handle_feed and\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}